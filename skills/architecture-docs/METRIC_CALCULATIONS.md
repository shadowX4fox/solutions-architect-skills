# Metric Calculations

> Algorithms for metric extraction, consistency checking, and index updates in ARCHITECTURE.md files

## Purpose

This document provides detailed algorithms for:
1. **Automatic Index Updates**: Calculate line ranges for Document Index
2. **Metric Consistency Detection**: Extract, scan, and classify metrics across the document

## Related Documentation

- **SKILL.md**: Operational workflows and when to trigger these calculations
- **ARCHITECTURE_DOCUMENTATION_GUIDE.md**: Content templates and what metrics to document
- **DESIGN_DRIVER_CALCULATIONS.md**: Design Drivers calculation algorithms

---

## 1. Automatic Index Updates

### Overview

The Document Index (typically lines 5-21 of ARCHITECTURE.md) provides quick navigation with exact line ranges for all sections. When content changes shift section boundaries by >10 lines, the index must be updated.

### When to Update

**Update the Document Index if:**
- ✅ Added/removed content that shifts section boundaries (>10 lines)
- ✅ Added/removed entire subsections or major content blocks
- ✅ Modified section headers or restructured sections
- ✅ User explicitly requests: "update the index" or "update document index"

**Do NOT update if:**
- ❌ Minor edits (<10 lines) within a section that don't shift other sections
- ❌ Only updating metadata (dates, version numbers, single values)
- ❌ Fixing typos or formatting issues

### Line Range Calculation Algorithm

**Step 1: Detect Section Boundaries**

Run bash command to find all numbered section headers:
```bash
grep -n "^## [0-9]" ARCHITECTURE.md
```

This returns output like:
```
25:## 1. Executive Summary
54:## 2. System Overview
147:## 3. Architecture Principles
301:## 4. Architecture Layers
...
```

**Step 2: Parse Grep Output**

Extract section numbers and line positions:
```
Section 1 starts at line 25
Section 2 starts at line 54
Section 3 starts at line 147
Section 4 starts at line 301
...
Section 12 starts at line 1917
```

**Step 3: Calculate Line Ranges**

For each section:
- **Start line**: Section header line number
- **End line**: (Next section's start line - 1)
- **Last section**: Use "end" or calculate from file length

Format: `Lines START-END`

**Calculation Example:**
```
Section 1: Lines 25-53  (from line 25 to 54-1)
Section 2: Lines 54-146 (from line 54 to 147-1)
Section 3: Lines 147-300 (from line 147 to 301-1)
Section 4: Lines 301-600 (from line 301 to 601-1)
...
Section 12: Lines 1917-end (last section)
```

**Step 4: Generate Index Content**

Build markdown list with calculated ranges:
```markdown
- [Section 1: Executive Summary](#1-executive-summary) → Lines 25-53
- [Section 2: System Overview](#2-system-overview) → Lines 54-146
- [Section 3: Architecture Principles](#3-architecture-principles) → Lines 147-300
...
```

**Step 5: Update Document Index**

1. Use Edit tool to replace the Quick Navigation list (typically lines 8-19)
2. Update `**Index Last Updated:**` to current date (YYYY-MM-DD format)
3. Preserve exact markdown formatting

### Complete Example Workflow

**Scenario**: After adding Confluent Kafka to Section 8, the section grew by 16 lines

```
1. Detect change: Section 8 grew from 906-980 to 912-996 (16 lines added)

2. Run: grep -n "^## [0-9]" ARCHITECTURE.md

3. Parse output:
   Section 1: Line 25
   Section 2: Line 54
   ...
   Section 8: Line 912 (shifted from 906)
   Section 9: Line 998 (shifted from 982)
   Section 10: Line 1244 (shifted from 1228)
   ...
   Section 12: Line 1923 (shifted from 1907)

4. Calculate ranges:
   Section 8: Lines 912-997 (912 to 998-1)
   Section 9: Lines 998-1243 (998 to 1244-1)
   Section 10: Lines 1244-1417 (1244 to next-1)
   ...

5. Update index:
   - [Section 8: Technology Stack](#8-technology-stack) → Lines 912-997
   - [Section 9: Security Architecture](#9-security-architecture) → Lines 998-1243
   - [Section 10: Scalability & Performance](#10-scalability--performance) → Lines 1244-1417
   - **Index Last Updated:** 2025-01-29

6. Report to user:
   "✅ Document Index updated - Sections 8-12 line ranges adjusted after Technology Stack expansion"
```

### Verification Checklist

After updating index, verify:
- ✅ All 12 sections are listed (or 11 if Data Flow omitted)
- ✅ Line ranges are sequential (no gaps or overlaps)
- ✅ Anchor links match actual section headers exactly
- ✅ "Index Last Updated" date is current (YYYY-MM-DD)
- ✅ Format matches template (consistent spacing and symbols)

### Edge Cases

**Case 1: Section Removed**
- Renumber subsequent sections
- Update all line ranges
- Update anchor links to match new section numbers

**Case 2: Section Added**
- Insert new section in index
- Renumber subsequent sections if needed
- Recalculate all affected line ranges

**Case 3: File Has No Index**
- Create new index from template
- Calculate all line ranges
- Insert at top of document (after title, before Section 1)

---

## 2. Metric Consistency Detection

### Overview

The Executive Summary (Section 1, Key Metrics subsection) contains performance metrics that serve as the **Source of Truth** for system capacity, throughput, latency, and availability targets. These metrics are often duplicated across multiple sections. When metrics are updated in the Executive Summary, duplicates in other sections can become stale, creating inconsistencies.

This algorithm provides automatic metric consistency detection and classification.

### When to Trigger

**Automatic Trigger:**
- ✅ After editing Section 1 Executive Summary Key Metrics (typically lines 31-38)
- ✅ When user updates any metric values in Key Metrics subsection
- ✅ After Edit tool completes on lines in Section 1 that contain metrics (TPS, latency, SLA, etc.)

**Manual Trigger:**
- ✅ User requests: "check metrics", "verify metrics", "audit metrics", "metric consistency"
- ✅ User requests: "find duplicates", "check for stale metrics"

### Metric Extraction & Registry Building

**Step 1: Extract Executive Summary Metrics**

Read ONLY lines 30-40 (Key Metrics section) using context-efficient approach:
```bash
Read(file_path="ARCHITECTURE.md", offset=30, limit=10)
```

**Step 2: Parse Metrics Using Regex Patterns**

| Metric Type | Regex Pattern | Example Match |
|-------------|---------------|---------------|
| **Average Read TPS** | `Average\s+Read\s+TPS:\s*(\d{1,3}(?:,\d{3})*)\s*transactions/second` | "Average Read TPS: 1,500 transactions/second" |
| **Peak Read TPS** | `Peak\s+Read\s+TPS:\s*(\d{1,3}(?:,\d{3})*)\s*transactions/second` | "Peak Read TPS: 3,000 transactions/second" |
| **Average Processing TPS** | `Average\s+Processing\s+TPS:\s*(\d{1,3}(?:,\d{3})*)\s*transactions/second` | "Average Processing TPS: 450 transactions/second" |
| **Peak Processing TPS** | `Peak\s+Processing\s+TPS:\s*(\d{1,3}(?:,\d{3})*)\s*transactions/second` | "Peak Processing TPS: 1,000 transactions/second" |
| **Average Write TPS** | `Average\s+Write\s+TPS:\s*(\d{1,3}(?:,\d{3})*)\s*transactions/second` | "Average Write TPS: 300 transactions/second" |
| **Peak Write TPS** | `Peak\s+Write\s+TPS:\s*(\d{1,3}(?:,\d{3})*)\s*transactions/second` | "Peak Write TPS: 800 transactions/second" |
| **Measurement Period** | `Measurement\s+Period:\s*(.+)` | "Measurement Period: Average over last 30 days" |
| **Percentile Latency** | `p(\d{2})\s*<\s*(\d+)ms` | "p95 < 100ms", "p99 < 200ms" |
| **Availability SLA** | `(\d{2,3}\.\d+)\s*%` | "99.99%", "99.9%" |
| **Concurrent Jobs** | `(\d{1,3}(?:,\d{3})*)\+?\s*concurrent` | "10,000+ concurrent", "5000 concurrent" |
| **Jobs per Hour** | `\[(\d{1,3}(?:,\d{3})*)\s*jobs?/hour\]` | "[1,620,000 jobs/hour]" |
| **Daily Volume** | `(\d{1,3}(?:,\d{3})*)\+?\s*(?:per\s*day\|daily)` | "500,000+ per day", "1,000,000 daily" |

**Step 3: Build Metrics Registry**

Extract all metrics and store in structured format:
```
METRICS_REGISTRY = [
  {name: "Read TPS", value: 1500, unit: "TPS", category: "Read", stat_type: "Average", line: 32, measurement_period: "Average over last 30 days in production"},
  {name: "Read TPS", value: 3000, unit: "TPS", category: "Read", stat_type: "Peak", line: 33, measurement_period: "Peak observed during Black Friday 2024"},
  {name: "Processing TPS", value: 450, unit: "TPS", category: "Processing", stat_type: "Average", line: 35, measurement_period: "Average over last quarter"},
  {name: "Processing TPS", value: 1000, unit: "TPS", category: "Processing", stat_type: "Peak", line: 36, measurement_period: "Peak during end-of-month batch processing"},
  {name: "Write TPS", value: 300, unit: "TPS", category: "Write", stat_type: "Average", line: 38, measurement_period: "Average over last month"},
  {name: "Write TPS", value: 800, unit: "TPS", category: "Write", stat_type: "Peak", line: 39, measurement_period: "Peak during data migration events"},
  {name: "System Availability", value: 99.99, unit: "%", line: 42, context: "SLA target"},
  {name: "Latency p95", value: 100, unit: "ms", line: 43, context: "response time"},
  {name: "Latency p99", value: 200, unit: "ms", line: 43, context: "response time"},
  {name: "Concurrent Jobs", value: 10000, unit: "jobs", line: 44, context: "concurrency limit"}
]
```

### Document Scanning & Match Detection

**Step 4: Scan Document for Metric References**

For each metric in registry, use Grep to find all occurrences:

```bash
# Example searches for TPS metrics (new standardized format)
Grep(pattern="Average\s+Read\s+TPS:\s*1,?500", path="ARCHITECTURE.md", output_mode="content", -n=True)
Grep(pattern="Peak\s+Read\s+TPS:\s*3,?000", path="ARCHITECTURE.md", output_mode="content", -n=True)
Grep(pattern="Average\s+Processing\s+TPS:\s*450", path="ARCHITECTURE.md", output_mode="content", -n=True)
Grep(pattern="Peak\s+Processing\s+TPS:\s*1,?000", path="ARCHITECTURE.md", output_mode="content", -n=True)
Grep(pattern="Average\s+Write\s+TPS:\s*300", path="ARCHITECTURE.md", output_mode="content", -n=True)
Grep(pattern="Peak\s+Write\s+TPS:\s*800", path="ARCHITECTURE.md", output_mode="content", -n=True)

# Example searches for other metric types
Grep(pattern="99\.99%", path="ARCHITECTURE.md", output_mode="content", -n=True)
Grep(pattern="p95.*100ms", path="ARCHITECTURE.md", output_mode="content", -n=True)
Grep(pattern="p99.*200ms", path="ARCHITECTURE.md", output_mode="content", -n=True)
Grep(pattern="10,?000.*concurrent", path="ARCHITECTURE.md", output_mode="content", -n=True)
```

**Note**: Use context-aware patterns to reduce false positives. For example:
- ❌ Bad: `grep "100"` (matches section numbers, version 1.00, etc.)
- ✅ Good: `grep "p95.*100ms"` (context-specific pattern)

**Step 5: Load Context for Each Match**

For each grep result, read ±5 lines for context:
```bash
# If match found at line 787
Read(file_path="ARCHITECTURE.md", offset=782, limit=10)
# Reads lines 782-792 to understand context
```

### Classification Algorithm

**Step 6: Classify Each Finding**

For each match, determine relationship to source metric:

**Classification Logic**:
```
1. IF match line is in Section 1 (lines 25-53):
   SKIP (this is the source of truth)

2. Read context (±5 lines) to understand metric meaning

3. Compare metric concept:
   - Same metric name/concept → potential duplicate
   - Different context → likely unrelated

4. Classify:
   IF (same value AND same concept):
      → ✓ Exact Match (consistent)

   ELSE IF (same concept AND different value):
      → ⚠️ Mismatch (ACTION REQUIRED)

   ELSE IF (mathematical transformation detected):
      → ℹ️ Derived Value (informational)
      Example: 450 TPS × 3600 = 1,620,000 jobs/hour

   ELSE:
      → ? Ambiguous (manual review needed)
```

**Derived Value Detection**:
Common transformations to check:
- TPS → jobs/hour: multiply by 3600
- TPS → jobs/day: multiply by 86400
- Percentage → fraction: divide by 100
- ms → seconds: divide by 1000

### Report Generation

**Step 7: Generate Consistency Report**

Present findings in structured format:

```markdown
═══════════════════════════════════════════════════════════
   METRIC CONSISTENCY AUDIT REPORT
═══════════════════════════════════════════════════════════
Source of Truth: Section 1 (Executive Summary) Lines 31-38
Total Metrics Audited: 8
Scan Date: 2025-01-29
═══════════════════════════════════════════════════════════

## ✓ Exact Matches (Consistent)

| Metric | Exec Value | Location | Context | Status |
|--------|-----------|----------|---------|--------|
| Job Latency (p95) | < 100ms | Line 787 | Section 6: Data Flow Performance | ✓ Match |
| Job Latency (p99) | < 200ms | Line 787 | Section 6: Data Flow Performance | ✓ Match |
| Job Latency (p95) | < 100ms | Line 1345 | Section 10: Performance Table | ✓ Match |
| Job Latency (p99) | < 200ms | Line 1345 | Section 10: Performance Table | ✓ Match |

## ⚠️ Mismatches Found (ACTION REQUIRED)

| Metric | Exec Value | Location | Current Value | Difference |
|--------|-----------|----------|---------------|------------|
| Peak Job Creation | 1,000 TPS | Line 1367 | 500 TPS | -500 TPS |

## ℹ️ Derived Values (Informational)

| Metric | Exec Value | Location | Derived Value | Relationship |
|--------|-----------|----------|---------------|--------------|
| Job Creation | 450 TPS | Line 32 | 1,620,000 jobs/hour | 450 × 3600 |

## ? Ambiguous Matches (Review Needed)

| Metric Pattern | Location | Context | Recommendation |
|----------------|----------|---------|----------------|
| "1000 TPS" | Line 1389 | Capacity planning note | Verify if refers to Peak Job Creation |

═══════════════════════════════════════════════════════════
SUMMARY: ✓ 4 Exact | ⚠️ 1 Mismatch | ℹ️ 1 Derived | ? 1 Ambiguous
═══════════════════════════════════════════════════════════
```

### Common Metric Locations

**Known Duplicate Locations** (typical architecture documents):

| Metric | Executive Summary | Common Duplicate Locations |
|--------|------------------|---------------------------|
| Average Read TPS | Line ~32 | Section 10 Throughput Table (~line 1367) |
| Peak Read TPS | Line ~33 | Section 10 Throughput Table (~line 1367) |
| Average Processing TPS | Line ~35 | Section 10 Throughput Table (~line 1368), Section 6 Data Flow (~line 787) |
| Peak Processing TPS | Line ~36 | Section 10 Throughput Table (~line 1368) |
| Average Write TPS | Line ~38 | Section 10 Throughput Table (~line 1369) |
| Peak Write TPS | Line ~39 | Section 10 Throughput Table (~line 1369) |
| System Availability (%) | Line ~42 | Section 2 Use Case metrics (~line 115), Section 7 Integration SLA Table (~lines 829-832) |
| Latency Targets (p95/p99) | Line ~43 | Section 6 Data Flow Performance (~line 787), Section 10 Performance Table (~line 1345) |
| Concurrent Jobs | Line ~44 | Less commonly duplicated (usually only in Exec Summary) |

**Note**: Line numbers are approximate and vary by document. Use grep to find exact locations.

### Edge Cases & Error Handling

**Case 1: Multiple Conflicting Values**

Scenario: Same metric has different values in multiple sections

Example:
- Exec Summary (Line 35): Average Processing TPS: 450 transactions/second
- Section 6 (Line 787): Average Processing TPS: 500 transactions/second
- Section 10 (Line 1367): Average Processing TPS: 400 transactions/second

**Handling**:
```
⚠️ CONFLICT DETECTED: Average Processing TPS has 3 different values

| Location | Value | Context |
|----------|-------|---------|
| Line 35 (Exec Summary) | 450 TPS | Design Capacity |
| Line 787 (Section 6) | 500 TPS | Data Flow Performance |
| Line 1367 (Section 10) | 400 TPS | Throughput Table |

Options:
1. Use Exec Summary (450 TPS) as source of truth
2. Manual review - investigate each context
```

**Case 2: Derived Value Calculation Errors**

Scenario: Derived value doesn't match expected conversion

Example:
- Exec Summary: 450 TPS
- Expected: 1,620,000 jobs/hour (450 × 3600)
- Found: 1,650,000 jobs/hour

**Handling**:
```
ℹ️ Derived Value Mismatch:
Base: 450 TPS (Line 32)
Expected: 1,620,000 jobs/hour
Found: 1,650,000 jobs/hour (Line 32)
Difference: +30,000 jobs/hour

Possible causes:
- Rounding or overhead factor
- Different calculation method
- Stale value
```

**Case 3: Ambiguous Context**

Scenario: Number matches but unclear if same metric

**Handling**:
```
? AMBIGUOUS MATCH: "1,000 TPS" found in multiple contexts

Exec Summary (Line 34):
"Peak Capacity: 1,000 TPS job creation"

Found Matches:
1. Line 1367: "System limit 1,000 TPS"
   → Likely same metric ✓

2. Line 1389: "1000 TPS limit"
   → Context unclear, review needed
```

**Case 4: No Matches Found**

Scenario: Metric exists in Exec Summary but never referenced elsewhere

**Handling**:
```
ℹ️ INFORMATIONAL: Metric appears only in Executive Summary

Metric: Concurrent Jobs (10,000+)
Location: Line 38 (Section 1)
Coverage: Not referenced in other sections

Recommendation:
- If important: Add to Section 10 (Scalability & Performance)
- If summary-only: No action needed
```

**Case 5: Too Many False Positives**

Scenario: Common number matches unrelated contexts

**Mitigation**:
- Use context-aware grep patterns
- ❌ Avoid: `grep "100"` (too broad)
- ✅ Use: `grep "p95.*100ms"` (context-specific)
- ✅ Use: `grep "100\s*TPS"` (unit-specific)

---

## Best Practices

### DO:
- ✅ Always scan full document after Exec Summary metric changes
- ✅ Present findings before making any changes (review-only first)
- ✅ Explain context for each mismatch (section, table/paragraph)
- ✅ Use context-aware grep patterns to reduce false positives
- ✅ Load ±5 lines context for each match
- ✅ Show exact before/after text for transparency
- ✅ Update Document Index if edits shift section boundaries

### DON'T:
- ❌ Auto-update without user approval (always review first)
- ❌ Change metrics in unrelated sections without confirming
- ❌ Ignore ambiguous matches (always flag for review)
- ❌ Forget to check derived values (TPS → jobs/hour conversions)
- ❌ Skip context loading (always read ±5 lines)
- ❌ Use overly broad grep patterns

---

## Implementation Notes

**Context Efficiency**:
- Load sections incrementally (Document Index, then Section 1, then search results)
- Avoid loading entire document (>2000 lines)
- Use Grep tool for searches (more efficient than full file reads)
- Load ±5 line context only for confirmed matches

**User Interaction**:
- Always present report before making changes
- Offer options: Update Exec, Update Document, Ignore, Manual Review
- Show preview with exact before/after text
- Confirm user approval before applying changes

**Workflow Integration**:
- Automatically trigger after Section 1 Key Metrics edits
- Update Document Index if changes shift line numbers (>10 lines)
- Report completion summary with all changes made